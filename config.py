import os
from langchain_community.tools import Tool
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader, PyPDFLoader


class Config:
    # æ¨¡å‹é…ç½® - å¯ä»¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–äº‘ç«¯API
    LOCAL_LLM = True  # è®¾ä¸ºFalseå¯ä½¿ç”¨OpenAIç­‰äº‘ç«¯æœåŠ¡

    # å‘é‡æ•°æ®åº“é…ç½®
    PERSIST_DIRECTORY = "chroma_db"
    EMBEDDING_MODEL = "./all-mpnet-base-v2"

    # çŸ¥è¯†åº“è·¯å¾„
    KNOWLEDGE_BASE_PATH = "./knowledge_docs"

    @classmethod
    def init_embeddings(cls):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        return HuggingFaceEmbeddings(model_name=cls.EMBEDDING_MODEL)


class LibraryTools:
    """å›¾ä¹¦é¦†æ™ºèƒ½ä½“å¯ç”¨çš„å·¥å…·é›†"""

    def __init__(self):
        self.vectorstore = None
        self.init_tools()

    def init_tools(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        embeddings = Config.init_embeddings()

        # å¦‚æœå‘é‡æ•°æ®åº“ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        if not os.path.exists(Config.PERSIST_DIRECTORY):
            self._create_vectorstore(embeddings)
        else:
            self.vectorstore = Chroma(
                persist_directory=Config.PERSIST_DIRECTORY,
                embedding_function=embeddings
            )

    def _create_vectorstore(self, embeddings):
        """åˆ›å»ºå‘é‡æ•°æ®åº“"""
        documents = []

        # åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£
        if os.path.exists(Config.KNOWLEDGE_BASE_PATH):
            for filename in os.listdir(Config.KNOWLEDGE_BASE_PATH):
                file_path = os.path.join(Config.KNOWLEDGE_BASE_PATH, filename)
                try:
                    if filename.endswith(".pdf"):
                        loader = PyPDFLoader(file_path)
                    else:
                        loader = TextLoader(file_path)
                    documents.extend(loader.load())
                except Exception as e:
                    print(f"Error loading {filename}: {e}")

        if documents:
            # åˆ†å‰²æ–‡æœ¬
            text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            texts = text_splitter.split_documents(documents)

            # åˆ›å»ºå‘é‡å­˜å‚¨
            self.vectorstore = Chroma.from_documents(
                documents=texts,
                embedding=embeddings,
                persist_directory=Config.PERSIST_DIRECTORY
            )
        else:
            # åˆ›å»ºç©ºçš„å‘é‡å­˜å‚¨
            self.vectorstore = Chroma(
                embedding_function=embeddings,
                persist_directory=Config.PERSIST_DIRECTORY
            )

    def search_knowledge_base(self, query: str) -> str:
        """æœç´¢çŸ¥è¯†åº“å·¥å…·"""
        # æ”¹è¿›çš„çŸ¥è¯†åº“æœç´¢å·¥å…·
        if self.vectorstore is None:
            return "çŸ¥è¯†åº“å°šæœªåˆå§‹åŒ–"

        try:
            # ä½¿ç”¨æ›´æ™ºèƒ½çš„æœç´¢
            docs = self.vectorstore.similarity_search(query, k=5)
            if not docs:
                # å°è¯•è¯­ä¹‰ç›¸è¿‘çš„æœç´¢
                return "åœ¨çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚å»ºè®®ï¼š1. æ£€æŸ¥å…³é”®è¯æ‹¼å†™ 2. å°è¯•æ›´é€šç”¨çš„æœ¯è¯­"

            results = ["ğŸ“š çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼š"]
            for i, doc in enumerate(docs, 1):
                content = doc.page_content
                # ç®€åŒ–å’Œæ ¼å¼åŒ–è¾“å‡º
                if len(content) > 500:
                    content = content[:500] + "..."
                results.append(f"{i}. {content}")

            return "\n".join(results)
        except Exception as e:
            return f"æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

    def search_book_catalog(self, query: str) -> str:
        """æ¨¡æ‹Ÿå›¾ä¹¦ç›®å½•æœç´¢å·¥å…·"""
        # è¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºçœŸå®çš„å›¾ä¹¦é¦†APIè°ƒç”¨
        mock_books = [
            {"title": "æ·±åº¦å­¦ä¹ ", "author": "Ian Goodfellow", "year": 2016,
             "category": "è®¡ç®—æœºç§‘å­¦", "call_number": "TP181/G646", "status": "å¯å€Ÿ"},
            {"title": "Pythonç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µ", "author": "Eric Matthes", "year": 2016,
             "category": "ç¼–ç¨‹", "call_number": "TP311.56/M429", "status": "å¯å€Ÿ"},
            {"title": "äººå·¥æ™ºèƒ½ï¼šç°ä»£æ–¹æ³•", "author": "Stuart Russell", "year": 2020,
             "category": "è®¡ç®—æœºç§‘å­¦", "call_number": "TP18/R961", "status": "å¯å€Ÿ"},
            {"title": "ç»Ÿè®¡å­¦ä¹ æ–¹æ³•", "author": "æèˆª", "year": 2019,
             "category": "è®¡ç®—æœºç§‘å­¦", "call_number": "TP181/L175", "status": "å¯å€Ÿ"},
            {"title": "æœºå™¨å­¦ä¹ ", "author": "å‘¨å¿—å", "year": 2016,
             "category": "è®¡ç®—æœºç§‘å­¦", "call_number": "TP181/Z774", "status": "å€Ÿå‡º"},
            {"title": "ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ", "author": "Michael Nielsen", "year": 2019,
             "category": "è®¡ç®—æœºç§‘å­¦", "call_number": "TP183/N669", "status": "å¯å€Ÿ"},
        ]

        # æ”¹è¿›çš„æœç´¢é€»è¾‘
        results = []
        query_lower = query.lower()

        for book in mock_books:
            # å¤šå­—æ®µåŒ¹é…
            match_score = 0
            if any(keyword in book['title'].lower() for keyword in ['æ·±åº¦å­¦ä¹ ', 'æœºå™¨å­¦ä¹ ', 'äººå·¥æ™ºèƒ½'] if
                   keyword in query_lower):
                match_score += 2
            if any(keyword in book['title'].lower() for keyword in query_lower.split()):
                match_score += 1
            if any(keyword in book['author'].lower() for keyword in query_lower.split()):
                match_score += 1
            if any(keyword in book['category'] for keyword in ['è®¡ç®—æœº', 'ç¼–ç¨‹', 'æ™ºèƒ½'] if keyword in query_lower):
                match_score += 1

            if match_score > 0:
                results.append((match_score, book))

        # æŒ‰åŒ¹é…åº¦æ’åº
        results.sort(key=lambda x: x[0], reverse=True)

        if results:
            output = ["ğŸ“– å›¾ä¹¦æ£€ç´¢ç»“æœï¼š"]
            for score, book in results[:3]:  # è¿”å›å‰3ä¸ªç»“æœ
                output.append(
                    f"Â· ã€Š{book['title']}ã€‹ - {book['author']} ({book['year']})\n"
                    f"  ç±»åˆ«: {book['category']} | ç´¢ä¹¦å·: {book['call_number']} | çŠ¶æ€: {book['status']}"
                )
            return "\n".join(output)
        else:
            return "æœªæ‰¾åˆ°ç›¸å…³å›¾ä¹¦ã€‚å»ºè®®ï¼š1. æ£€æŸ¥ä¹¦åæˆ–ä½œè€…å 2. å°è¯•æ›´é€šç”¨çš„æœç´¢è¯"

    def get_tools(self):
        """è¿”å›æ‰€æœ‰å·¥å…·"""
        return [
            Tool(
                name="knowledge_base_search",
                func=self.search_knowledge_base,
                description="ç”¨äºåœ¨å›¾ä¹¦é¦†çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯"
            ),
            Tool(
                name="book_catalog_search",
                func=self.search_book_catalog,
                description="ç”¨äºåœ¨å›¾ä¹¦ç›®å½•ä¸­æœç´¢ä¹¦ç±"
            )
        ]