import os
from langchain_community.tools import Tool
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader, PyPDFLoader
import numpy as np
import requests
from langchain_core.embeddings import Embeddings


class Config:
    # æ¨¡å‹é…ç½®
    SILICONFLOW_API_KEY = "sk-aiijdfbzalmwidpetzrzopatkbeotqaxsnuixggvmcvxutcd"
    EMBED_MODEL = "BAAI/bge-m3"
    LLM_MODEL = "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
    SILICONFLOW_API_BASE = "https://api.siliconflow.cn/v1"

    # å‘é‡æ•°æ®åº“é…ç½®
    FAISS_INDEX_PATH = "././faiss_renewed_index"
    BOOKS_DATA_PATH = "./book_embeddings_renewed.csv"  # ä¹¦ç±æ•°æ®æ–‡ä»¶

    # çŸ¥è¯†åº“è·¯å¾„
    KNOWLEDGE_BASE_PATH = "./knowledge_docs"


class SiliconFlowEmbeddings(Embeddings):
    """ç¡…åŸºæµåŠ¨åµŒå…¥æ¨¡å‹ - ä¿®å¤ç‰ˆ"""

    def __init__(self, model_name=Config.EMBED_MODEL, api_key=Config.SILICONFLOW_API_KEY):
        self.model_name = model_name
        self.api_key = api_key
        self.api_url = "https://api.siliconflow.cn/v1/embeddings"
        self.dimension = 1024

    def embed_query(self, text):
        """ä¸ºæŸ¥è¯¢ç”ŸæˆåµŒå…¥å‘é‡"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model_name,
            "input": [text],
            "encoding_format": "float"
        }

        try:
            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            return result["data"][0]["embedding"]
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            return np.random.normal(0, 0.1, self.dimension).tolist()

    def embed_documents(self, texts):
        """ä¸ºæ–‡æ¡£ç”ŸæˆåµŒå…¥å‘é‡"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…è¯·æ±‚è¿‡å¤§
        batch_size = 10
        all_embeddings = []

        total_batches = (len(texts) + batch_size - 1) // batch_size
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            batch_num = i // batch_size + 1
            print(f"  ç”Ÿæˆæ–‡æ¡£åµŒå…¥æ‰¹æ¬¡ {batch_num}/{total_batches}")

            data = {
                "model": self.model_name,
                "input": batch_texts,
                "encoding_format": "float"
            }

            try:
                response = requests.post(self.api_url, headers=headers, json=data, timeout=60)
                response.raise_for_status()
                result = response.json()
                batch_embeddings = [item["embedding"] for item in result["data"]]
                all_embeddings.extend(batch_embeddings)
            except Exception as e:
                print(f"  âŒ æ–‡æ¡£åµŒå…¥æ‰¹æ¬¡å¤±è´¥: {e}")
                # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡ç”Ÿæˆéšæœºå‘é‡
                all_embeddings.extend([np.random.normal(0, 0.1, self.dimension).tolist() for _ in batch_texts])

            # é¿å…APIé™åˆ¶
            if batch_num < total_batches:
                import time
                time.sleep(1)

        return all_embeddings


class LibraryTools:
    """å›¾ä¹¦é¦†æ™ºèƒ½ä½“å¯ç”¨çš„å·¥å…·é›†"""

    def __init__(self):
        self.vectorstore = None
        self.embeddings = SiliconFlowEmbeddings()
        self.init_tools()

    def init_tools(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        # å¦‚æœFAISSç´¢å¼•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        if not os.path.exists(Config.FAISS_INDEX_PATH):
            self._create_books_vectorstore()
        else:
            self.vectorstore = FAISS.load_local(
                Config.FAISS_INDEX_PATH,
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"ğŸ“‚ åŠ è½½FAISSä¹¦ç±ç´¢å¼•æˆåŠŸ")

    # config.py ä¸­çš„ _create_books_vectorstore æ–¹æ³•æ›¿æ¢ä¸ºï¼š

    def _create_books_vectorstore(self):
        """åˆ›å»ºåŸºäºä¹¦ç±æ•°æ®çš„FAISSå‘é‡æ•°æ®åº“"""
        import pandas as pd

        # æ£€æŸ¥ä¹¦ç±æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(Config.BOOKS_DATA_PATH):
            print(f"âŒ ä¹¦ç±æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {Config.BOOKS_DATA_PATH}")
            # åˆ›å»ºç©ºçš„å‘é‡å­˜å‚¨
            self.vectorstore = FAISS.from_texts(
                texts=["æš‚æ— ä¹¦ç±æ•°æ®"],
                embedding=self.embeddings
            )
            self.vectorstore.save_local(Config.FAISS_INDEX_PATH)
            print(f"ğŸ’¾ åˆ›å»ºç©ºFAISSç´¢å¼•: {Config.FAISS_INDEX_PATH}")
            return

        try:
            # è¯»å–ä¹¦ç±æ•°æ®
            df = pd.read_csv(Config.BOOKS_DATA_PATH, encoding="utf-8-sig")
            print(f"ğŸ“– è¯»å–åˆ° {len(df)} æ¡ä¹¦ç±æ•°æ®")

            # å‡†å¤‡æ•°æ®
            texts = []
            metadatas = []

            success_count = 0
            for idx, row in df.iterrows():
                try:
                    # æ£€æŸ¥å¿…è¦å­—æ®µ
                    if "text" not in row or "embedding" not in row:
                        continue

                    text = str(row["text"]).strip()
                    if not text:
                        continue

                    # è§£æç°æœ‰çš„åµŒå…¥å‘é‡ï¼ˆé¿å…é‡æ–°ç”Ÿæˆï¼‰
                    embedding_str = str(row["embedding"]).strip()
                    try:
                        embedding = list(map(float, embedding_str.split(",")))
                        if len(embedding) != 1024:
                            continue
                    except:
                        continue

                    texts.append(text)
                    metadatas.append({
                        "title": str(row.get("title", "æ— é¢˜å")),
                        "author": str(row.get("author", "æœªçŸ¥ä½œè€…")),
                        "publisher": str(row.get("publisher", "æœªçŸ¥å‡ºç‰ˆç¤¾")),
                        "year": str(row.get("year", "æœªçŸ¥å¹´ä»½")),
                        "chunk_id": str(row.get("chunk_id", str(idx))),
                        "book_id": str(row.get("book_id", str(idx)))
                    })
                    success_count += 1

                    # é™åˆ¶æ•°æ®é‡ç”¨äºæµ‹è¯•
                    if success_count >= 10000:  # æœ€å¤š1ä¸‡æ¡ç”¨äºæµ‹è¯•
                        break

                except Exception as e:
                    continue

            print(f"âœ… å‡†å¤‡ {success_count} æ¡æœ‰æ•ˆè®°å½•")

            if success_count == 0:
                raise Exception("æ²¡æœ‰æœ‰æ•ˆçš„ä¹¦ç±æ•°æ®")

            # ä½¿ç”¨ç°æœ‰çš„åµŒå…¥å‘é‡åˆ›å»ºFAISSç´¢å¼•
            print("ğŸ”„ ä½¿ç”¨ç°æœ‰åµŒå…¥å‘é‡åˆ›å»ºFAISSç´¢å¼•...")

            # æå–åµŒå…¥å‘é‡
            embeddings_list = []
            for idx, row in df.head(success_count).iterrows():
                try:
                    embedding_str = str(row["embedding"]).strip()
                    embedding = list(map(float, embedding_str.split(",")))
                    if len(embedding) == 1024:
                        embeddings_list.append(embedding)
                    else:
                        # å¦‚æœåµŒå…¥å‘é‡æ— æ•ˆï¼Œä½¿ç”¨é›¶å‘é‡
                        embeddings_list.append([0.0] * 1024)
                except:
                    embeddings_list.append([0.0] * 1024)

            # åˆ›å»ºFAISSç´¢å¼•
            import numpy as np
            self.vectorstore = FAISS.from_embeddings(
                text_embeddings=list(zip(texts, embeddings_list)),
                embedding=self.embeddings,
                metadatas=metadatas
            )

            # ä¿å­˜ç´¢å¼•
            self.vectorstore.save_local(Config.FAISS_INDEX_PATH)
            print(f"ğŸ’¾ ä¹¦ç±FAISSç´¢å¼•å·²ä¿å­˜åˆ°: {Config.FAISS_INDEX_PATH}")
            print(f"ğŸ“š ç´¢å¼•åŒ…å«: {success_count} æœ¬ä¹¦ç±")

        except Exception as e:
            print(f"âŒ åˆ›å»ºä¹¦ç±å‘é‡åº“å¤±è´¥: {e}")
            # åˆ›å»ºç©ºçš„å‘é‡å­˜å‚¨ä½œä¸ºé™çº§æ–¹æ¡ˆ
            self.vectorstore = FAISS.from_texts(
                texts=["ä¹¦ç±æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥"],
                embedding=self.embeddings
            )
            self.vectorstore.save_local(Config.FAISS_INDEX_PATH)

    # æ›¿æ¢ config.py ä¸­çš„ search_knowledge_base æ–¹æ³•ï¼š

    def search_knowledge_base(self, query: str) -> str:
        """æœç´¢çŸ¥è¯†åº“å·¥å…· - åŸºäºä¹¦ç±æ•°æ®"""
        if self.vectorstore is None:
            return "ä¹¦ç±æ•°æ®åº“å°šæœªåˆå§‹åŒ–"

        try:
            print(f"ğŸ” æœç´¢æŸ¥è¯¢: '{query}'")
            docs = self.vectorstore.similarity_search(query, k=10)  # å¢åŠ æ£€ç´¢æ•°é‡
            print(f"ğŸ“„ æ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")

            if not docs:
                return "æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±ä¿¡æ¯"

            results = []
            seen_books = set()

            for i, doc in enumerate(docs):
                title = doc.metadata.get('title', 'æ— é¢˜å')
                author = doc.metadata.get('author', 'æœªçŸ¥ä½œè€…')
                book_key = f"{title}-{author}"

                # å»é‡
                if book_key in seen_books:
                    continue
                seen_books.add(book_key)

                publisher = doc.metadata.get('publisher', 'æœªçŸ¥å‡ºç‰ˆç¤¾')
                year = doc.metadata.get('year', 'æœªçŸ¥å¹´ä»½')

                book_info = f"ã€Š{title}ã€‹\n   ä½œè€…: {author}"
                if publisher != 'æœªçŸ¥å‡ºç‰ˆç¤¾':
                    book_info += f"\n   å‡ºç‰ˆç¤¾: {publisher}"
                if year != 'æœªçŸ¥å¹´ä»½':
                    book_info += f"\n   å‡ºç‰ˆå¹´: {year}"

                # æ·»åŠ å†…å®¹é¢„è§ˆ
                content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                book_info += f"\n   ç®€ä»‹: {content_preview}"

                results.append(book_info)

                # æœ€å¤šè¿”å›8æœ¬ä¹¦
                if len(results) >= 8:
                    break

            return "\n\n".join(results) if results else "æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±"

        except Exception as e:
            print(f"âŒ æœç´¢é”™è¯¯: {e}")
            return f"æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

    def search_book_catalog(self, query: str) -> str:
        """å›¾ä¹¦ç›®å½•æœç´¢å·¥å…· - å¢å¼ºç‰ˆ"""
        if self.vectorstore is None:
            return "ä¹¦ç±æ•°æ®åº“å°šæœªåˆå§‹åŒ–"

        try:
            # ä½¿ç”¨å‘é‡æœç´¢æ‰¾åˆ°ç›¸å…³ä¹¦ç±
            docs = self.vectorstore.similarity_search(query, k=8)
            if not docs:
                return "æœªæ‰¾åˆ°ç›¸å…³å›¾ä¹¦"

            # æŒ‰ä½œè€…å’Œç±»åˆ«åˆ†ç»„
            author_books = {}
            category_books = {}

            for doc in docs:
                title = doc.metadata.get('title', 'æ— é¢˜å')
                author = doc.metadata.get('author', 'æœªçŸ¥ä½œè€…')
                publisher = doc.metadata.get('publisher', 'æœªçŸ¥å‡ºç‰ˆç¤¾')
                year = doc.metadata.get('year', 'æœªçŸ¥å¹´ä»½')

                # æŒ‰ä½œè€…åˆ†ç»„
                if author not in author_books:
                    author_books[author] = []
                author_books[author].append(f"ã€Š{title}ã€‹({year})")

                # ç®€å•åˆ†ç±»ï¼ˆæ ¹æ®æŸ¥è¯¢å…³é”®è¯ï¼‰
                if "å°è¯´" in query or "æ–‡å­¦" in query:
                    category = "æ–‡å­¦å°è¯´"
                elif "å†å²" in query:
                    category = "å†å²"
                elif "ç§‘å­¦" in query or "æŠ€æœ¯" in query:
                    category = "ç§‘å­¦æŠ€æœ¯"
                else:
                    category = "å…¶ä»–"

                if category not in category_books:
                    category_books[category] = []
                category_books[category].append(f"ã€Š{title}ã€‹ - {author}")

            # æ„å»ºç»“æœ
            results = []

            if author_books:
                results.append("æŒ‰ä½œè€…åˆ†ç±»:")
                for author, books in list(author_books.items())[:3]:  # æœ€å¤š3ä¸ªä½œè€…
                    results.append(f"  {author}: {', '.join(books[:3])}")

            if category_books:
                results.append("\næŒ‰ç±»åˆ«åˆ†ç±»:")
                for category, books in category_books.items():
                    results.append(f"  {category}: {', '.join(books[:3])}")

            return "\n".join(results) if results else "æœªæ‰¾åˆ°ç›¸å…³å›¾ä¹¦"

        except Exception as e:
            return f"ç›®å½•æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

    def get_tools(self):
        """è¿”å›æ‰€æœ‰å·¥å…·"""
        return [
            Tool(
                name="knowledge_base_search",
                func=self.search_knowledge_base,
                description="ç”¨äºåœ¨å›¾ä¹¦é¦†çŸ¥è¯†åº“ä¸­æœç´¢ä¹¦ç±ç›¸å…³ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¹¦åã€ä½œè€…ã€å‡ºç‰ˆç¤¾ç­‰"
            ),
            Tool(
                name="book_catalog_search",
                func=self.search_book_catalog,
                description="ç”¨äºåœ¨å›¾ä¹¦ç›®å½•ä¸­æœç´¢ä¹¦ç±ï¼Œæä¾›æŒ‰ä½œè€…å’Œåˆ†ç±»çš„æœç´¢ç»“æœ"
            )
        ]